#!/bin/bash

# Distributed Training Cleanup Script for SmolLM3-3B Fine-tuning
# Cleans up all distributed training resources

set -e

PYTORCHJOB_NAME="smollm3-distributed-finetuning"

echo "ğŸ§¹ Cleaning up Distributed Training Resources"
echo "=============================================="

# Function to check if PyTorchJob exists
check_job_exists() {
    kubectl get pytorchjob $PYTORCHJOB_NAME >/dev/null 2>&1
}

# Check current status
echo "ğŸ” Checking current distributed training status..."

if check_job_exists; then
    echo "ğŸ“Š Current PyTorchJob status:"
    kubectl get pytorchjob $PYTORCHJOB_NAME -o wide

    echo ""
    echo "ğŸ“‹ Current pods:"
    kubectl get pods -l pytorch-job-name=$PYTORCHJOB_NAME -o wide

    echo ""
    read -p "âš ï¸  Do you want to delete the PyTorchJob and all associated pods? [y/N]: " confirm

    if [[ $confirm =~ ^[Yy]$ ]]; then
        echo "ğŸ—‘ï¸  Deleting PyTorchJob: $PYTORCHJOB_NAME"
        kubectl delete pytorchjob $PYTORCHJOB_NAME

        echo "â³ Waiting for pods to be cleaned up..."
        sleep 15

        # Check if any pods are still running
        echo "ğŸ” Checking for remaining pods..."
        remaining_pods=$(kubectl get pods -l pytorch-job-name=$PYTORCHJOB_NAME --no-headers 2>/dev/null | wc -l)

        if [ "$remaining_pods" -gt 0 ]; then
            echo "âš ï¸  Found $remaining_pods remaining pods. Force deleting..."
            kubectl delete pods -l pytorch-job-name=$PYTORCHJOB_NAME --force --grace-period=0 2>/dev/null || true
            sleep 10
        fi

        echo "âœ… PyTorchJob and pods deleted"
    else
        echo "âŒ Cleanup cancelled"
        exit 0
    fi
else
    echo "âœ… No PyTorchJob '${PYTORCHJOB_NAME}' found"
fi

# Check for any orphaned pods
echo ""
echo "ğŸ” Checking for orphaned pods..."
orphaned_pods=$(kubectl get pods -l pytorch-job-name=$PYTORCHJOB_NAME --no-headers 2>/dev/null | wc -l)

if [ "$orphaned_pods" -gt 0 ]; then
    echo "âš ï¸  Found $orphaned_pods orphaned pods:"
    kubectl get pods -l pytorch-job-name=$PYTORCHJOB_NAME

    read -p "ğŸ—‘ï¸  Delete orphaned pods? [y/N]: " confirm_orphaned

    if [[ $confirm_orphaned =~ ^[Yy]$ ]]; then
        kubectl delete pods -l pytorch-job-name=$PYTORCHJOB_NAME --force --grace-period=0
        echo "âœ… Orphaned pods deleted"
    fi
else
    echo "âœ… No orphaned pods found"
fi

# Ask about PVC cleanup
echo ""
echo "ğŸ“¦ Storage cleanup options:"
kubectl get pvc

echo ""
read -p "ğŸ—‘ï¸  Do you want to clean up PVCs (this will delete all training data and models)? [y/N]: " confirm_pvc

if [[ $confirm_pvc =~ ^[Yy]$ ]]; then
    echo "âš ï¸  Deleting all PVCs - this will permanently delete training data and models!"
    read -p "Are you absolutely sure? Type 'DELETE' to confirm: " final_confirm

    if [[ $final_confirm == "DELETE" ]]; then
        kubectl delete pvc trained-models-pvc workspace-pvc 2>/dev/null || echo "Some PVCs may not exist"
        echo "âœ… PVCs deleted"
    else
        echo "âŒ PVC cleanup cancelled"
    fi
else
    echo "ğŸ“¦ PVCs preserved (models and data intact)"
fi

# Clean up temporary files
echo ""
echo "ğŸ§¹ Cleaning up temporary deployment files..."
if [ -f "pytorchjob-temp.yaml" ]; then
    rm pytorchjob-temp.yaml
    echo "âœ… Removed pytorchjob-temp.yaml"
fi

echo ""
echo "âœ… Distributed training cleanup complete!"
echo ""
echo "ğŸ“‹ Summary:"
echo "- PyTorchJob deleted: âœ…"
echo "- Pods cleaned up: âœ…"
echo "- Temp files removed: âœ…"
echo "- PVCs: $(if [[ $confirm_pvc =~ ^[Yy]$ ]] && [[ $final_confirm == "DELETE" ]]; then echo "Deleted"; else echo "Preserved"; fi)"

echo ""
echo "ğŸš€ To start a new distributed training run:"
echo "./deploy-script.sh"